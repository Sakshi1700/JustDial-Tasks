{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Text_keyword_Extraction.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Importing Libraries"
      ],
      "metadata": {
        "id": "kR7LE4aFqIHH"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Z81OYVpvp4ZT"
      },
      "outputs": [],
      "source": [
        "import numpy as np \n",
        "import pandas as pd\n",
        "import re\n",
        "import os\n",
        "import spacy\n",
        "import matplotlib.pyplot as plt"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install pytextrank\n",
        "import pytextrank\n",
        "\n",
        "import nltk\n",
        "nltk.download('omw-1.4')\n",
        "nltk.download('punkt')\n",
        "from nltk.tokenize import word_tokenize\n",
        "from nltk import pos_tag\n",
        "\n",
        "nltk.download('stopwords')\n",
        "from nltk.corpus import stopwords\n",
        "\n",
        "nltk.download('wordnet')\n",
        "from nltk.corpus import wordnet\n",
        "\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "wordnet_lemmatizer = WordNetLemmatizer()"
      ],
      "metadata": {
        "id": "dlF-G4jOyFtu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Importing the Dataset"
      ],
      "metadata": {
        "id": "trORPFlKynVg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "data = pd.read_csv('reviews.txt', sep='\\t')\n",
        "data.head()"
      ],
      "metadata": {
        "id": "AxJwGEOjymtv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Dropping the unwanted columns\n",
        "\n",
        "#mydata = data.drop('Unnamed: 0', axis=1)\n",
        "#mydata.head()\n"
      ],
      "metadata": {
        "id": "1BrLtyZvzmJJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Data Pre-Processing"
      ],
      "metadata": {
        "id": "Ijh0gCtJz1fu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Cleaning -> Tokenization -> POS tagging -> Stopwords removal -> Lemmatization\n",
        "\n",
        "# Define a function to clean the text\n",
        "def clean(text):\n",
        "    # Removes all special characters and numericals leaving the alphabets\n",
        "    text = re.sub('[^A-Za-z]+', ' ', text) \n",
        "    return text\n",
        "\n",
        "# Cleaning the text in the review column\n",
        "mydata['Cleaned Reviews'] = mydata['review'].apply(clean)\n",
        "\n",
        "pos_dict = {'J':wordnet.ADJ, 'V':wordnet.VERB, 'N':wordnet.NOUN, 'R':wordnet.ADV}\n",
        "\n",
        "def token_stop_pos(text):\n",
        "    tags = pos_tag(word_tokenize(text))\n",
        "    newlist = []\n",
        "    for word, tag in tags:\n",
        "        if word.lower() not in set(stopwords.words('english')):\n",
        "            newlist.append(tuple([word, pos_dict.get(tag[0])]))\n",
        "    return newlist\n",
        "\n",
        "mydata['POS tagged'] = mydata['Cleaned Reviews'].apply(token_stop_pos)\n",
        "\n",
        "def lemmatize(pos_data):\n",
        "    lemma_rew = \" \"\n",
        "    for word, pos in pos_data:\n",
        "        if not pos: \n",
        "            lemma = word\n",
        "            lemma_rew = lemma_rew + \" \" + lemma\n",
        "        else:  \n",
        "            lemma = wordnet_lemmatizer.lemmatize(word, pos=pos)\n",
        "            lemma_rew = lemma_rew + \" \" + lemma\n",
        "    return lemma_rew\n",
        "    \n",
        "mydata['Lemma'] = mydata['POS tagged'].apply(lemmatize)\n",
        "mydata.head()\n"
      ],
      "metadata": {
        "id": "_sgP7TIOz4zM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Extracting Keywords and Phrases"
      ],
      "metadata": {
        "id": "C5_7y_Z-2lo4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import spacy\n",
        "import pytextrank\n",
        "nlp = spacy.load('en_core_web_sm')\n",
        "tr = pytextrank.TextRank()\n",
        "nlp.add_pipe(tr.PipelineComponent, name='textrank', last=True)"
      ],
      "metadata": {
        "id": "jTu1b8hi07nY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "extracted = []\n",
        "\n",
        "for text in mydata['Lemma']:\n",
        "    text = nlp(text)\n",
        "    t = text._.phrases\n",
        "    extracted.append(t)\n",
        "    \n",
        "mydata['Pytextrank_keyword'] = extracted \n",
        "\n",
        "mydata['Pytextrank_keyword'] = mydata['Pytextrank_keyword'].agg(lambda x: ','.join(map(str, x)))"
      ],
      "metadata": {
        "id": "htDq7IK82s9Q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "New_Data = mydata[['review','sentiment','Pytextrank_keyword']]"
      ],
      "metadata": {
        "id": "L399VUHr4FCI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "New_Data.head()"
      ],
      "metadata": {
        "id": "LfN_B_s441b4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Saving the CSV File"
      ],
      "metadata": {
        "id": "ZryMIDcc46xS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "1LHwhs8o4-at"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}